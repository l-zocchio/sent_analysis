{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sent_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWVABXjm6_9R"
      },
      "source": [
        "# CNN para análise de sentimento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wInfeCyv7F1q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "200b8e1d-6072-4264-d1dd-400d6694fe02"
      },
      "source": [
        "# Obs.: run before everything and then restart the runtime!\n",
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=a41d3e474526aa42249b038571f247dd57738595fbddc2e4144a8ac2b8b3ccb8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1cc3b88i/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chkdU17I-5N7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4017303c-ee60-49cb-d149-0130bd75befd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#create DataFrame with commmentaries and number of stars\n",
        "data_path = '/content/drive/My Drive/data/'\n",
        "df = pd.read_csv(data_path+'comentarios_dados.csv',sep=';')\n",
        "print(\"File loaded sucessfully!\")\n",
        "df = pd.concat([df, pd.get_dummies(df['n° estrelas'],prefix='estrelas')], axis=1) \n",
        "df.drop(['n° estrelas'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File loaded sucessfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xzDB09-_CKz"
      },
      "source": [
        "# divide texts and labels\n",
        "text_data = df['conteúdo'].to_numpy()\n",
        "label_data = df[['estrelas_1', 'estrelas_2', 'estrelas_3', 'estrelas_4', 'estrelas_5']].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQjBZA6FBXE4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "71bf28ad-d56e-43cd-dfcf-77d21799f9e2"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "!pip install unidecode\n",
        "from unidecode import unidecode\n",
        "# word lemmatization (base form)\n",
        "def lemmatizer(text:str) -> str:\n",
        "    sent = []\n",
        "    doc = nlp(text)\n",
        "    for word in doc:\n",
        "        if word.pos_ in [\"VERB\"]:\n",
        "            sent.append(word.lemma_)\n",
        "        else:\n",
        "            sent.append(word.orth_)\n",
        "    return \" \".join(sent)\n",
        "\n",
        "# text standardization\n",
        "def text_padr(text:str) -> str:\n",
        "    text = text.strip().replace('\\n', '')\n",
        "    text = text.lower()\n",
        "    text = unidecode(text)\n",
        "    text = lemmatizer(text)\n",
        "    return text\n",
        "\n",
        "from tqdm import tqdm\n",
        "text_data = [text_padr(str(text)) for text in tqdm(text_data)]\n",
        "\n",
        "print(\"\\nText standardization concluded!\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|                                                                             | 17/206785 [00:00<20:53, 165.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in c:\\users\\gilen\\anaconda3\\lib\\site-packages (1.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████| 206785/206785 [23:09<00:00, 148.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Text standardization concluded!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA3glpryIwnu"
      },
      "source": [
        "# save lemmatized text data\n",
        "import pickle\n",
        "\n",
        "data_path = '/content/drive/My Drive/data/'\n",
        "with open(f'{data_path}lemmatized_texts.pickle','wb') as f:\n",
        "    pickle.dump(text_data, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyh0Anh0-hl1"
      },
      "source": [
        "# load lemmatized text data\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open(data_path+'lemmatized_texts.pickle','rb') as f:\n",
        "    text_data = np.asarray(pickle.load(file=f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb417jKSPuS3"
      },
      "source": [
        "g_path='/content/drive/My Drive/data/glove_s100.txt'\n",
        "with open(g_path,'r') as f:\n",
        "    g_file = f.readlines()[1:]\n",
        "    with open('file_for_aug_model.txt','w') as gf:\n",
        "        gf.writelines(g_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_SGzM9H_zRe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "83c06205-0bdd-4851-abd6-8c01898cfe3b"
      },
      "source": [
        "# data balanced with random undersampling\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "runsamp = RandomUnderSampler(sampling_strategy='auto')\n",
        "text_data = np.expand_dims(text_data, axis=-1)\n",
        "print(\"balancing data...\")\n",
        "text_data, label_data = runsamp.fit_resample(text_data, label_data)\n",
        "# return text_data list to its original shape\n",
        "text_data = np.squeeze(text_data)\n",
        "print(f\"data undersampling concluded! Total number of examples: {len(text_data)} \")\n",
        "\n",
        "print(\"Mean text length: \", np.mean([len(txt) for txt in text_data]),\"\\n\",\n",
        "      \"Standard deviation: \", np.std([len(txt) for txt in text_data]), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "balancing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "data undersampling concluded! Total number of examples: 29065 \n",
            "Mean text length:  191.5015654567349 \n",
            " Standard deviation:  159.117799494289 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvo9RkdK9Ia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3c99fed9-0431-4612-fa54-40050e33a206"
      },
      "source": [
        "!pip install nlpaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qq8KMhaBjBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8682a050-8c3d-41b1-e9c6-a5e700684a5b"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(np.array([np.argmax(lbl) for lbl in label_data]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f59d5a6b630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3RV55X4/e9WR42igipI9C4BAneDO8ZY4MZgO3YmsYMniWcyzrwzSeZN7NSVyXgmcTJxCXEcbMc2cQVh45Bgg8E0I0CiiSJAqAGSQEigrnuf3x9X8lJklSvp3KLD/qzFWrc8OmcfpLvvc54qxhiUUkoNfgG+DkAppZQ1NKErpZRNaEJXSimb0ISulFI2oQldKaVsQhO6UkrZRFBvBUTkJWARUGGMmdZNmfnAM0AwUGWMmdfbcWNjY01aWlqfglVKqcvd7t27q4wxcV2912tCB1YCvwVe6epNERkGPAcsMMYUi0i8O0GlpaWRm5vrTlGllFJtRORUd+/12uRijNkMnO+hyAPAu8aY4rbyFX2OUCml1IBZ0YY+ARguIptEZLeIPGzBMZVSSvWRO00u7hxjNnATMATYLiI7jDFHOxcUkeXAcoBRo0ZZcGqllFLtrKihlwLrjTF1xpgqYDOQ0VVBY8wKY0yWMSYrLq7LNn2llFL9ZEVCXwNcKyJBIhIOXAEUWHBcpZRSfeDOsMU3gPlArIiUAk/hGp6IMeYFY0yBiPwF2Ac4gReNMQc8F7JSSqmu9JrQjTH3u1HmaeBpSyJSSinVLzpTVCmlbEITulJK2YQVwxYvW6/vLO7x/QeuGJxDM3u6rsF6Tb3Ra/57g/Wa7fqZdJfW0JVSyiY0oSullE1oQldKKZvQhK6UUjahCV0ppWxCE7pSStmEJnSllLIJTehKKWUTmtCVUsomNKErpZRNaEJXSimb0ISulFI2oQldKaVsQhO6UkrZhCZ0pZSyiV4Tuoi8JCIVItLjPqEiMkdEWkXkXuvCU0op5S53augrgQU9FRCRQOAXwF8tiEkppVQ/9JrQjTGbgfO9FPtn4B2gwoqglFJK9d2A29BFJBm4C3h+4OEopZTqLys6RZ8BvmOMcfZWUESWi0iuiORWVlZacGqllFLtrNgkOgtYJSIAscBCEWk1xqzuXNAYswJYAZCVlWUsOLdSSqk2A07oxpj09scishJ4v6tkrpRSyrN6Tegi8gYwH4gVkVLgKSAYwBjzgkejU0op5bZeE7ox5n53D2aM+ccBRaOUUqrfdKaoUkrZhCZ0pZSyCU3oSillE5rQlVLKJjShK6WUTWhCV0opm9CErpRSNqEJXSmlbEITulJK2YQmdKWUsglN6EopZROa0JVSyiY0oSullE1oQldKKZvQhK6UUjahCV0ppWxCE7pSStmEJnSllLKJXhO6iLwkIhUicqCb9x8UkX0isl9EtolIhvVhKqWU6o07NfSVwIIe3j8JzDPGTAd+AqywIC6llFJ95M4m0ZtFJK2H97d1eLoDSBl4WEoppfrK6jb0R4APu3tTRJaLSK6I5FZWVlp8aqWUurxZltBF5AZcCf073ZUxxqwwxmQZY7Li4uKsOrVSSincaHJxh4jMAF4EbjfGnLPimEoppfpmwDV0ERkFvAs8ZIw5OvCQlFJK9UevNXQReQOYD8SKSCnwFBAMYIx5AXgSiAGeExGAVmNMlqcCVkop1TV3Rrnc38v7jwKPWhaRUkqpftGZokopZROa0JVSyiY0oSullE1oQldKKZvQhK6UUjahCV0ppWxCE7pSStmEJnSllLIJTehKKWUTmtCVUsomNKErpZRNaEJXSimb0ISulFI2oQldKaVsQhO6UkrZhCZ0pZSyCU3oSillE70mdBF5SUQqRORAN++LiPxGRApFZJ+IzLI+TKWUUr1xp4a+EljQw/u3A+Pb/i0Hnh94WEoppfqq14RujNkMnO+hyGLgFeOyAxgmIolWBaiUUso9VrShJwMlHZ6Xtr2mlFLKi7zaKSoiy0UkV0RyKysrvXlqpZSyPSsSehmQ2uF5SttrX2CMWWGMyTLGZMXFxVlwaqWUUu2sSOg5wMNto12uBGqMMactOK5SSqk+COqtgIi8AcwHYkWkFHgKCAYwxrwArAMWAoVAPfAVTwWrlFKqe70mdGPM/b28b4BvWhaRUkqpftGZokopZROa0JVSyiY0oSullE1oQldKKZvQhK6UUjahCV0ppWxCE7pSStmEJnSllLIJTehKKWUTmtCVUsomNKErpZRNaEJXSimb0ISulFI2oQldKaVsQhO6UkrZhCZ0pZSyCU3oSillE5rQlVLKJtxK6CKyQESOiEihiHy3i/dHichGEdkrIvtEZKH1oSqllOpJrwldRAKBZ4HbgSnA/SIypVOx7wNvGmNmAsuA56wOVCmlVM/cqaHPBQqNMSeMMc3AKmBxpzIGiG57PBQoty5EpZRS7ghyo0wyUNLheSlwRacyPwT+KiL/DEQAN1sSnVJKKbdZ1Sl6P7DSGJMCLAReFZEvHFtElotIrojkVlZWWnRqpZRS4F5CLwNSOzxPaXuto0eANwGMMduBMCC284GMMSuMMVnGmKy4uLj+RayUUqpL7iT0XcB4EUkXkRBcnZ45ncoUAzcBiMhkXAldq+BKKeVFvSZ0Y0wr8DiwHijANZrloIj8WESy24r9G/A1EckH3gD+0RhjPBW0UkqpL3KnUxRjzDpgXafXnuzw+BBwjbWhKaWU6gudKaqUUjahCV0ppWxCE7pSStmEJnSllLIJTehKKWUTmtCVUsomNKErpZRNaEJXSimb0ISulFI2oQldKaVsQhO6UkrZhCZ0pZSyCU3oSillE5rQlVLKJjShK6WUTWhCV0opm9CErpRSNqEJXSmlbMKthC4iC0TkiIgUish3uymzVEQOichBEXnd2jCVUkr1ptc9RUUkEHgWuAUoBXaJSE7bPqLtZcYD3wOuMcZUi0i8pwJWSinVNXdq6HOBQmPMCWNMM7AKWNypzNeAZ40x1QDGmAprw1RKKdUbdxJ6MlDS4Xlp22sdTQAmiMhWEdkhIgusClAppZR7em1y6cNxxgPzgRRgs4hMN8Zc6FhIRJYDywFGjRpl0amVUkqBezX0MiC1w/OUttc6KgVyjDEtxpiTwFFcCf7vGGNWGGOyjDFZcXFx/Y1ZKaVUF9xJ6LuA8SKSLiIhwDIgp1OZ1bhq54hILK4mmBMWxqmUUqoXvSZ0Y0wr8DiwHigA3jTGHBSRH4tIdlux9cA5ETkEbAT+3RhzzlNBK6WU+iK32tCNMeuAdZ1ee7LDYwN8u+2fUkopH9CZokopZROa0JVSyiY0oSullE1oQldKKZvQhK6UUjahCV0ppWxCE7pSStmEJnSllLIJTehKKWUTmtCVUsomNKErpZRNaEJXSimb0ISulFI2oQldKaVsQhO6UkrZhCZ0pZSyCU3oSillE5rQlVLKJtxK6CKyQESOiEihiHy3h3L3iIgRkSzrQvRPxhgcTuPrMLymxeHEaS6f670cGGNocTh9HYbXOC+Dz2yve4qKSCDwLHALUArsEpEcY8yhTuWigG8BOz0RqD/ZdryK/3h7H1WXmpiUEE1GyjAmJkT5OizLOY3hYHkteSUXOHr2IiPCQ5icGM3s0cN9HZpHlF9oYOORClodBhGYkzaCyYnRvg7LI0rO1/PS1pMcr6wjLSacGSnDmD16OMGB9rtpL6tuYHdxNYfKa/jFh4f5waIp3JeVgoj4OjTLufPbmwsUGmNOGGOagVXA4i7K/QT4BdBoYXx+pdXh5EdrD/LA73cSHBjAlMRojpy5yMvbi9h96ryvw7PcxiMVvPFZMWXV9cxJG06Lw8m9L2zj5x8WYGxWWy+trufFT09wsqqOS02tnKlp5E87TpFXcsHXoVnurdwSbv3VZkqrG7hyTAz1zQ5y8stZtavElr/XFzYfZ/ep86QMD2dyUjT/8c4+Hn05l5r6Fl+HZ7lea+hAMlDS4XkpcEXHAiIyC0g1xnwgIv/e3YFEZDmwHGDUqFF9j9bHVm4r4o9bi3j4qtF87/bJvLe3DIfT8MdtJ1mTV07C0CEkDxvi6zAtcaziIh8XVJCZOox7Z6cQIMKtUxwcPlPL7z45weSEaJbMTPZ1mJbYW1zNHz49SXhIII9eN4bh4SE0tzp5eXsRb+WWcOWYEdw9K8XXYVqi4HQt3313P3PShnP9+DiGhYdgjGFrYRXrDpzh08Iqrhsf5+swLVHX1MprO4uJCgvim/PHEREaxLI5qfxxWxH/9WEBP1x7kF/9Q6avw7TUgO+vRCQA+CXwb72VNcasMMZkGWOy4uIG1x9N2YUGfvm3o9w4KZ4fZU9lSEggAIEBwrI5o4gIDeL1naeob271caQDV9PQwp93lRAXFcqSzGQC2m5Nw4ID+fndM5g5ahg/fv8Q5+uafRzpwDW2OHj89b1EhAbxtbZkDhASFMCXr0ojPS6C77yzj+Jz9T6OdOAcTsN339nHsCHBvPCl2Qxru1YR4ZpxsUxNimb9wTOcrKrzcaQD5zSGP+8qoa6plQfnjiYi1FV3DQgQHrk2na/PG8t7e8vYcqzSx5Fay52EXgakdnie0vZauyhgGrBJRIqAK4EcO3WMGmN4as0BjIEfZU/9QttbZGgQD8wdRW1DK+sPnvVRlNZZk1dGq9PwwBWjCAn6+z+RwADh53dPp7ahhZ99UOCjCK3zyvYiyi40cNfM5M8TXLuQoACWzk4lMEB4+q9HfBOghV7ZXkR+aQ1P3jnlC9cqItwzK4Xh4SG8vbtk0HeW5hZVU1h5ieyMJJKHf/Gu+Rs3jCM9NoLvrz5AY4vDBxF6hjsJfRcwXkTSRSQEWAbktL9pjKkxxsQaY9KMMWnADiDbGJPrkYh9YP3Bs2woqODbt0wgdUR4l2VSR4QzO204e4qrqWkYvG1zh8prOXzmItePjyM+KqzLMpMSovmneWN5Z08p24+f83KE1rlQ38xvPy5k/sQ4xsZFdlkmekgwj147hrX55ewrHbzt6WdrG3l6/RHmT4wjOyOpyzJhwYEsmpFIdX0La/LKvRyhdRxOwydHK0gZPqTbDvyw4EB+tmQap87V89uPC70coef0mtCNMa3A48B6oAB40xhzUER+LCLZng7Q14wx/OajY4yNi+Ar16T1WPb68XEYY/h0EN/GPf/JcUKDArhqTEyP5R6/cRzxUaE8t2nwfhie23Sci02tfGfBpB7LPTZvDCMiQvj5usODttNw5bYiGlscXd5hdjRhZBSJQ8N4blPhoB3it6/0AtX1LdwwMb7Ha716XCyLZiTyx60nqW0cvJWwjtxqQzfGrDPGTDDGjDXG/KzttSeNMTldlJ1vp9r5ZyfPc+h0LY9cO4agXoZ0jYgIITN1GJ8VnedS0+BrSz9ZVccH+8q5Ij3m8z6C7oQFB/LwVaPZcqyKY2cveilC61TUNrJyWxF3z0zpdWhiVFgw/3LjOLafOMfWwsF3R9LQ7OCNz4q5dUoCo2MieiwrIsybEMeJyjr+evCMlyK0jtMYNh2pJCE6zK2hxMuvH0Nds4O3cku9EJ3n2W/QqcVWbitiWHgwd7k5omPehHhaHa5RA4PN7z45TnBgANeM67l23u7+ua429j9uK/JsYB6walcJza1O/vnGcW6Vf+CK0cRGhvDK9iKPxuUJq/PKuFDf0usdZrtpyUNJj43g2U2Fg+6O5GB5LZWXmpg/Me7zzvyetI+/f3lb0aC9I+lIE3oPSqvrWX/wDMvmjOq1xtouLiqUqUnR7Dx5blB1tlRdauKdPaUszUolKizYrZ+JiQxlSWYS7+4p5UL94Bnx4nAaVn1WzHXjY0mL7bnG2i4kKIB7Z6fy0eEKztQMnqkWxhj+uPUkU5OimZs+wq2fCRDh6/PGcqCsdtD1kWwtrCImIoRpyUPd/pmvXJNG8fl6Nh6u8GBk3qEJvQevbj+FiPDQVaP79HNXjImhscXJ+kF0y7p6bxktDsPDfbzWr1yTTmOLk1W7Snov7Cc2HamgvKaRB+b2bS7EA3NH4XC6hsMNFlsLz3H07CW+ck16n2ZGZmcmER0WxJu5g+daCysuUny+nrnpI9yqnbe7bWoCiUPD+OO2kx6Mzjs0oXejqdXBql0l3DZ1ZJ8nC6XHRjA8PHjQtMsZY3grt5SM1GGMH9m3JQwmJ0Zz1ZgYXt1+CucguWV9bWcxcVGh3DxlZJ9+blRMONeNj2XVrmJaB8mwvj/tOEVMRAh3ZiT26efCggPJzkziwwNnBk2H4Vu7SwkQyEwd1qefCw4M4KGrRrO18ByFFYOvP6gjTejd2HSkkpqGFpZmpfZeuJMAEWaNGs7W41WUnPf/CSn7y2o4cvYi983u32zIpXNSKLvQwK4i/1/+oLS6no1HKlg2J7Vf65Y8eMVoTtc0sumI/49kqmlo4ePDFWRnJhEa5F6TYUf3zU6lqdXJ+/mnPRCdtVocTt7ZXcbEkVFuNxl25JoNDe/uKeu9sB/ThN6NNXllxESEcO242H79/Ky28a/v7PH/WvpbuaWEBgVwZzfjk3tz29QEwkMCeW+v/38Y3my7a/qHOX3/oga4aXI8I6NDef2zYivD8oj1B87Q7HCyJLN/SzTMSBnKhJGRvLXb/5tdPjlSSdWlJmaPdq+foLP4qDCuGx/HmrzyQXOn2RVN6F242NjChoIKFs1I7HWoYneGh4dw9dgY3t5d6td/II0tDtbklXHb1ASGDul7zQYgPCSIBVMT+GD/ab/uCDbGsCavjGvGxpIyvOsJYr0JDgxgycxkPjlayblLTRZHaK01+WVtKym630HYkYhw3+xU9hZf8PumiLd2lxAbGTKgVU/vnpVM2YUGPhsEd5rd0YTehfUHz9Lc6mTxABefWpqVSml1AztO+u9IgQ0FZ6ltbOW+rIEtPnXXrGQuNrbyUYH/jhTYV1rDqXP13c6UdNeSzGQcTsO6/f7bFHG2tpFtx8+xODN5QMvELp6ZRGCA8NZu/73TPF/XzEcFFdw1M5nAgP5f6y1TRrruNAdxs4sm9C6sySsjdcQQZvaxc6WzW6ckEBESSI4fT6NevbechOgwrh7bv6aldlePjWVkdCjv7fXfD/6avHJCAgO4bVrCgI4zOTGaiSOjWO3Hv9e1+eUY4xqtMhDxUWHMmxDHWj9uivhg/2lanYa7Zg6sUhIeEsSCaQms8/M7zZ5oQu+k4mIjWwurWJwxsJoNwJCQQG6ZMpIPD5yhudX/RkXU1LfwyVFX09JAajbgWrRrSWYym45U+uUqjA6n4f195cyfGNfvpqWOFs9MYvepar/t9F6TV8705KHdrlHTF9kZSZTXNLKnuNqCyKy3Nr+ccfGRTE4c+CYzd89M4WKTf99p9kQTeicf7DuN08CSmQOr2bTLzkyipqHFL5fpXH/wDC0O0+/O0M6WzEym1Wn4wA+bInaeOEfFxSYW97ODsLP2Zps1ef53e3688hL7y2pYPMDaebubp4wkNCiAnHz/uyM5XeMaXZWdkWTJDkRXjY1pu9P0v9+rOzShd7I6r5wpidGMi7dmS7lrx7lqhP74YcjJL2f0ADrNOpuUEMX4+EjW+mFTRE5+OREhgdw0Od6S46UMD2du2ghW55X73fT4NXnliGDZF3VkaBA3Tx7Juv2n/W78/fv5pzHGumsNDBAWzUjik6MVg3JHI03oHRRV1ZFfcsGymg24powvnJ7A3w6dpaHZf9rlKi82se14lWU1G3CNisjOSOKzovOUX2iw5JhWaGp1sG7/aW6bmkBYcN/HY3dn8cwkCisucbC81rJjDpQxhpy8Mq4aE8PI6K6XP+6POzOSqLrUzPYT/tXBv3afq2kp3c0lHNyRnZFEi8Pwl4P+d6fZG03oHeTku2o2A+1I6uzOjCTqmx18dNh/Nr9Yt9/VtGRVzaZd+/He3+c/tfRPjlRS29jKnRb/XhdOSyQoQPyq2WVfaQ1F5+r7Pfa8O/MnxhEVGuRXHfwnq+rYV1oz4FFLnc1IGcromHC/vKvujSb0NsYYVueVMTdtBIlDrd0X9Ir0GOKjQv3qw5CTX86khCgm9HGqf2/SYiPISBnqVx+GnPxyRgxgklh3hkeEMH9iHDn55X6zUt/qvDJLRvJ0FhYcyK1TE/jLwTM0tfrHnebatr+xRX1c1qA37Xea24+fo+Li4FmIDTShf+5geS0nKuss6zTrKDBAuGNG4ufLCfhaaXU9u09VW147b5edmcyBslqOV17yyPH7oq6plQ0FZ1k4PaFfU/17szgzmbO1Tez0g6YIh9OwNv80N06Kt2QkT2fZmUlcbGz1i2UPjDHk5Jd7pAIGrmYXp3ENkhhMNKG3WZNXRnCgsHC6tTWbdtkZSTQ7nH6xacD7bX+kd87wTEJfNCMREfzijuRvh87S2OL0yBc1wM2TRxIREshqP2h22Xa8iqpLTZb2AXV09dgYRkSEfF4z9qXDZy5SWHHJ8ma0duNHRjE5Mdqv7jTd4VZCF5EFInJERApF5LtdvP9tETkkIvtE5CMR6dsarD7mcLq+7edNiP/C5rlWyUwdxqgR/tEul5NX7oonpn/T33szMjqMK9Nj2ia3+LYpYk1eGUlDw5g9quu9JQdqSEggt01L4MP9Z3w+GWVNXjlRoUHcMMmakTydBQe6Ovg3FJylzsc7cuXklxMYICy0uGmpo+yMJPYWX6D4nH/ONehKrwldRAKBZ4HbgSnA/SIypVOxvUCWMWYG8Dbw31YH6kk7T57jbK3najbgape7MyORbcfPUeXDNUAKKy5x6HSt5R1JnWVnJnGiqs6nI0DO1zWz5VgVd2YmETDAiVM9WZKZzMWmVjYd8d1klMYWB385cIYF06wdydNZdkYyjS1ONhT4roPfGMPa/HKuHRdLTGSox87TvuTwWj/q4O+NOzX0uUChMeaEMaYZWAUs7ljAGLPRGNP+NbYDGNgcXC/LyXONUb55ct/Wx+6rOzOSfL4GyNq2kTx3zLC2I6mz26clEBwoPr0jaZ8S7ukvr6vHxhAbGcrqvb671o8PV3CpqdVjTUvtskYPJ3FomE+bXfYUX6C0usFjfUDtUoaHM3v0cL9oOnSXOwk9Gei4fmZp22vdeQT4cCBBeVPHMcrubjPXX5MSopkwMtJnH4b2ms2V6daOUe7KsPAQrh8fx9p8360B8u6eUiaOjGJKL5tAD1RQYAB3ZiTy8eEKn3V6r8krIy4qlKvGurcfbH8FBAiLZiTyydFKn207uDa/nJCgAG6b6tkKGLiaXY6cvciRM/692mQ7SztFReRLQBbwdDfvLxeRXBHJraz0fU85uDayqG1stXzseXeyM5LYVeSbNUAOlNVyoqrOe9eamcTpmkafbHxxsqqOvcUXuHvWwNfkccfizGSaHU7+csD7d1819S1sPFzJnTOSBrwmjzuyM5JpcRg+POD9Dv5Wh5P3953mxonx/drIoq8WTk8kQCAn3/ed3u5wJ6GXAR13A0hpe+3viMjNwP8PZBtjumwkNsasMMZkGWOy4uLi+hOv5XLyyge0kUVfLZmZjPhoZ5S3d5e4Zq5O82xzS7ubJ48kLNg3a4C8t8e1HdmSAS6B7K6MlKGkxYT7pNnlLwdP0+xwerQPqKNpydGMi4/kbR8sqfvJUddGFnfP8s7vNS4qlGvGxbI2/7TPO/jd4U5C3wWMF5F0EQkBlgE5HQuIyEzgd7iS+aBZpsy1kcXZAW1k0Vcpw8NdG1/sKfFqU0RTq4M1+eWujSzCPV+zAYjosAaIN1ebdDoN7+4t45pxsR5vWmonIizOTGbHyXOcqfHuZJT39paRHhth2Zo8vXFtfJHC7lPVXp9r8FZuKbGRIR4bydOV7Iwkis/Xs7fkgtfO2V+9ZjFjTCvwOLAeKADeNMYcFJEfi0h2W7GngUjgLRHJE5Gcbg7nV3Lyy2lqdXqtFtfuvtmplJxvYOdJ7zVFbDhUwYX6ln7vG9pf98xOobq+xaujInYVnae0uoF7Znn3WpfMTMYY796eF1XVsePEee6e6Z2mpXZ3zXJtJuHNWvr5umY+OnyWJZnJHpkk1p3bpiUQFhwwKDZ9d+t/xRizzhgzwRgz1hjzs7bXnjTG5LQ9vtkYM9IYk9n2L7vnI/qHVZ+VMCkhqs+7hA/UbVMTiAoN8upejW/tLiFxaBjXeKlpqd314+NIHjaEN7y4B+e7e8qICAnkVi90mnWU3rbswXt7vTf+ftWuEgIDhPv6sZn5QMRHhTF/Qhzv7in12gqMq/eW0eIw3DvA3bX6KjosmDumJ5GTV+bz8fe9uWxnih4oq2F/WQ3L5qR6tWYDrskoizIS+XD/GS554Q/kTE0jm49Wcs+sFK90mnXkSjYpbDlW5ZWO4JqGFnLyy1k0I4nwkCCPn6+ze2enUHC6ljwv3J63OJy8vbuUGybGkzDUO01LHd2XlcLZ2ia2HKvyyvne3l3K9OShTErw7Kilrtw/N5W6ZodfLTrXlcs2ob/xWTGhQQED3raqv+6dnUpDi8MrQxjf2VOK07iSjS8szUolQODPuzx/R/LO7lIaWhw8dJVvJivfNSuFyNAgXt1+yuPn+qjgLFWXmnjgCu/WztvdOGkkIyJCeDPX87/XA2U1HDpdO+C9b/tr9ujhjI+P5PXPvHdX3R+XZUKvb25lTV45d0xP9FoHYWezRg1jUkIUL28r8ujteYvDyWs7TnHVmBjSLFwzui+Shg1h/sR43swt8ejtudNpeHXHKWaNGsa0ZO90EHYWGRrE3bOSeX/fac55eEbw65+5mtHmTfBeB2FHIUEB3DMrmb8eOuvx9e9XbitiSHAgizO829/VTkRYNncU+SUXKDjtP+vfd3ZZJvT3953mUlMry+aO8lkMIsJXr03n8JmLbC303Ep9Hx44Q3lNI49cm+6xc7jj/rmjqLjYxAYP7tX4aWEVJ6vq+PLVaR47hzseunI0zQ4nf/ZgzbXkfD1bjlWyNCvV681oHbX/X7+8rchj56i42EhOXjlLs1J8VgEDuHtmMiGBAV7tD+qryy6hO52GP2w5yYSRkcxJ88yCTe7KzkgiNjKEP3x6wiPHN8bw4pYTpMdGcKMXh3l15YaJcaQMH8LvNh/32B3JK9tPERsZwgIPLtjkjvEjo7h6bJJXESMAAA5aSURBVAyv7Sj22DrpKzafIChAuN+HlRJwDcO9fVoCr39W7LH+oD9tP0WL08lXrvFtpWR4RAiLZiTy9u5Sqv1wI3S4DBP6xiMVHDl7kX+aN9brnaGdhQUH8tCVaWw8UklhhfXjeXNPVbOvtIavXpvu0cWp3BEUGMBj88ayt/gCO05YP1yzqKqOjw6fZdmcUYQGeXYJB3c8fNVoyi40sN4DyyVXXGzkz7kl3DMrxSedoZ09et0YLja28pYH7kgaWxz8aWcxN08e6bMmw46WzxtDfbODl7cX+TqULl1WCd0Yw3ObjpM8bIjHF/Zx15euHEVIUAAvbT1p+bFf3HKCYeHB3OOlWXW9uW92CrGRoTy3qdDyY//6o2OEBQXy8NX+sXLzLVMSGBsXwTMbjlpeS3/p0yJaHU4emzfW0uP2V2bqMLJGD+elrSctv9b39pZxvq6ZR33cZNhuUkI0N02KZ+W2Iuqb/W8I42WV0HcVVbP7VDXLrx/j1YkJPYmJDOWeWSm8nVtq6bC+Q+W1/PXQWR68YpRPhu91JSw4kEevS2fLsSr2lVo3rO/Y2Yuszivjy1enER/l+xoruIZrPnHLBI6evWTpULeahhb+tOMUC6cnWrox8kA9et0YSs43sHqvdZOqGlscPLuxkBkpQ5mbPsKy4w7UN24Yy4X6Ft7wwxEv/pHVvOS5TYXERISw1MuTMHrzrZvGExAA/73+iCXHM8bws3WHGDokmOXX+Uctrt2DV4wiOiyI33xkXS39VxuOEhESxGPXj7HsmFZYOC2RSQlRPLPhmGWje1ZuLeJSUyvfmD/OkuNZ5dYpI8lIGcrT64/Q0GzNRh8vbyuitLqB7yyY5PPm0Y5mjx7B3PQRvLjlhN/sr9rusknonx6rYtORSh65Lt3jy+T2VcLQMJZfN4a1+eXsLa4e8PE2Hqlga+E5vnXTeJ+OCuhKVFgwj80by4aCs2y0YEOIA2U1rNt/hq9em87wCM/sNtVfAQHCt2+ZwMmqOksWYys5X8/znxRy+7QEpiR5f3JNTwIChO8vmsKZ2kZ+v2Xgnfzn65r57cZCbpwU7/XZze745xvHcbqmkZc+LfJ1KH/nskjoza1Onsw5QFpMOF/1cU95dx6bN5bYyFB++kHBgEaBtDic/OyDAsbERvClK/2jPbmzR69LZ0xcBE+tOTigbdtaHU6+v/oAw8KDfT4sszu3TBlJRuow/nv94QGNSzfG8FTOQQJE+MGizhuG+Yc5aSNYOD2B5zcd52ztwBYo+/WGo9Q3O/jPhZMsis5a142P45YpI/m/j49xusazY/D74rJI6C9tPcmJyjqeyp7q0e25BiIiNIh/u3UCu09Vs2oAMyp/v+UExyvr+N7CyX7TT9BZaFAgP10yjeLz9Ty7sf9NL7/bfIK8kgv8KHuqR3a5t4KI8It7plPb0Mr3Vx/o95f1+oNn+fhwBd++ZQJJw6zf5d4q31kwiVankx+vPdTva91TXM1rO4tZNieVcfFRFkdonScXTcHhNPz0gwJfh/I5//zEW6j8QgO/+egYt0wZyQ0TfTsWuzdLs1K5dlwsT+Uc5GB5TZ9/fseJc/zvX4+ycHoCN0/272u9emwsd81M5oVPjverg/RQeS3PbDjKHdMTPb7F3EBNSojmiVsm8OGBM/1aG77yYhM/zDnIpIQo/tHHk6Z6MzomgidumcAH+0/zSj+WP6iua+bx1/aQMDSM/7jNP2vn7VJHhPON+eP4YN9pPvXSeja9sXVCb2xx8PXX9iC4vk39XWCA8MyyTIaHB/ON1/ZQ2+j+dmYVtY08/vpeRo8I5xf3zPCrTqTufP+OyYyMDuOrK3P7NMKnuq6Zb63ay9AhIfxkybRBca3Lrx/D7NHD+cHqAxw96/52ZvXNrTzy8i5qGlr4n/syvLZu/0D80/VjuWlSPD/94BB7+tAn5HQanngzj6pLzTz/4Gy/6//pymPzxjAmNoIn3szz+jr4XfH/v45+Msbw5JoD5Jdc4H+XZpI6ItzXIbklNjKUZx+YRWl1A4+9stutPSqrLjXxtVd3U9fUyvNfmu2VrbmsEBMZysqvzKG51cFXVu6ipr73az1f18wDL+7k1Pl6fr0skxF+1hHancAA4VdLMwkLDuT+FTvc2qPS4TT8yxt7OVBWw//dP9Nn69P0VUCA8MulmSQMDePrf9rN4TO9r33S6nDygzUH2HSkkifvnMJ0L23WMVBhwYG88NBs6ptaeexPuwfUJ2QF2yb0P3x6kjdzS/mXG8f5fCp4X2WljeDpe2ewq+g89zy/jeJz3ddeD5+pZfFvt3L4dC2/XpbJxAT/bXPsyrj4KFY8nEXxuXruen4r+T0sO1t8rp4Hfr+DE5WXePHhLL8c/dCTUTHhrFp+JUGBwv2/30FuD3utll9o4KE/7GRDQQU/yp7KzVO8u7b7QA0ND+b3D2cBcM9z29hwqPsNTi42tvDIy7m8trOYx64fw4NX+HY5g76aMDKK/12aQX7JBf7zvf0eW+7BHbZL6MYY/mf9EX76QQG3ThnJv948wdch9cvds1J49ZErqLzYxKL/28J/fXj475olCisu8eO1h7j7uW20Op289U9XcevUwfXF1e7KMTGs/OocGpod3P38Nn7+YQEHympwOg0Op6H4XD0/ef8QN/1yE8Xn63nxy1lcP8E/9qTtqzFxkaxafhVDggO594XtfPO1PRwqr6W51YkxhpNVdby45QS3PbOZvJIL/OKe6Tx0VZqvw+6XSQnRrPnmtYyJi+Rrr+byr6v2sqvo/OedpRfqm/n95hPc/ustbC2s4ud3T+d7CycPiia0zhZMS+SJmyfw7p4yvvHabsvG4veV+Grj06ysLJObm2vpMWsbW/jB6gOsyStn2ZxUfrJkmkdHery+s+dV1x6woKZxsqqO//qwgA0FFTiNYUhwIALUNTsIDhRum5rA9++YYumaHj1dlxXX1J2ahhaeWnOA1XmujsOosCAaWxy0OAwisHR2Kt++dYJH9gn19jXXNbWyYvMJVmw+QUOLgwCBoUOCqW5rdpqTNpz/uS+D0TGemw3qrWtuaHbw9PojvJVbwsWmVsLb5oE0tTpxOA1z00bw7VsncOWYmAGfyxufyZ689OlJfvLBITJShvHbB2aSMtz6pl4R2W2MyerqPbfmhIvIAuDXQCDwojHmvzq9Hwq8AswGzgH/YIwpGkjQfdHqcLJqVwm//NtRquub+ffbJvKN+b5ffMsK6bER/O6hLE7XNPDe3jKq65pxGkiIDuOuWcnERob6OkTLDB0SzDPLZvKfd0xma2EVu4qqiQ4LJi0mnKy0EYyLj/R1iJaJCA3iiVsm8OAVo9hyrIpT5+upqG1kalI0146PIy0m3BZ/v+DaoevJO6fw/902gffzT3Pk7EUCxNX+vHB6IpMT/WuS1EB89dp0koYN4Yk/53Hj/37C165L5+vzxxEZ6p3lN3o9i4gEAs8CtwClwC4RyTHGHOpQ7BGg2hgzTkSWAb8A/sETAYOrN7zsQgOFFZf4W8FZ/nLgDOfrmpmbPoInF00ZNJ1HfZE4dIjfTff2lPioMO6ameKz3aS8KT46jHt8tJOUt4WHBLF0jn8tu+EJC6YlkJE6j198eJhnNx7npU+LuHFyPAumJjA5MZrRMeEeazlw52tjLlBojDkBICKrgMVAx4S+GPhh2+O3gd+KiBgPtOes23+aJ/6cR1Ora22MIcGB3DQ5nrtnJXPDxHjb1GqUUoNX4tAhPLNsJl+9Np0/7yrhLwfO8MG+04BrxNM354/l27dOtPy87iT0ZKDj1MVS4IruyhhjWkWkBogBLB9tPy4+koeuHM3Y+EjGxEYwI2WY363NopRSADNShjEjZRg/yp7KwfJajlde4njlJTJHDfPI+by6rqqILAeWtz29JCLWLC/oO7H08KX1oBcD8ZLYBz3wJe2nPv/d2vD32NkX/o7tes0P9vKZHSS6XaTJnYReBnRs+Eppe62rMqUiEgQMxdU5+neMMSuAFW6cc1AQkdzuepvt6HK6Xr1We7L7tbrTMr8LGC8i6SISAiwDcjqVyQG+3Pb4XuBjT7SfK6WU6l6vNfS2NvHHgfW4hi2+ZIw5KCI/BnKNMTnAH4BXRaQQOI8r6SullPIit9rQjTHrgHWdXnuyw+NG4D5rQxsUbNN85KbL6Xr1Wu3J1tfqs5miSimlrGW7tVyUUupypQm9n0RkgYgcEZFCEfmur+PxFBF5SUQqROSAr2PxNBFJFZGNInJIRA6KyLd8HZOniEiYiHwmIvlt1/ojX8fkaSISKCJ7ReR9X8fiKZrQ+6HDcgi3A1OA+0XE/3fQ6J+VwAJfB+ElrcC/GWOmAFcC37Tx77UJuNEYkwFkAgtE5Eofx+Rp3wL8Z784D9CE3j+fL4dgjGkG2pdDsB1jzGZcI5dszxhz2hizp+3xRVwf/mTfRuUZxuVS29Pgtn+27VATkRTgDuBFX8fiSZrQ+6er5RBs+cG/XIlIGjAT2OnbSDynrQkiD6gA/maMse21As8A/wE4fR2IJ2lCV6oTEYkE3gH+1RjT+/5pg5QxxmGMycQ1+3uuiEzzdUyeICKLgApjzG5fx+JpmtD7x53lENQgJCLBuJL5a8aYd30djzcYYy4AG7FvX8k1QLaIFOFqHr1RRP7k25A8QxN6/7izHIIaZMS19vIfgAJjzC99HY8niUiciAxrezwE134Hh30blWcYY75njEkxxqTh+qx+bIz5ko/D8ghN6P1gjGkF2pdDKADeNMYc9G1UniEibwDbgYkiUioij/g6Jg+6BngIVw0ur+3fQl8H5SGJwEYR2YergvI3Y4xth/NdLnSmqFJK2YTW0JVSyiY0oSullE1oQldKKZvQhK6UUjahCV0ppWxCE7pSStmEJnSllLIJTehKKWUT/w+fEPr40wr0fgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqlzcwrxg7_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b2cdf479-8b2c-4459-8a8f-d320843cc21f"
      },
      "source": [
        "!pip install nlpaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKac4HhEPldi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be8c86a4-086a-47e0-e360-2548adbdb5c6"
      },
      "source": [
        "# data augmentation using pretrained embeddings\n",
        "\n",
        "import nlpaug.augmenter.word as naw \n",
        "import nlpaug.model.word_embs as nmw\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Loading GloVe model...\")\n",
        "\n",
        "glove_model = nmw.GloVe()\n",
        "g_path=data_path+'glove_s100.txt'\n",
        "\n",
        "with open(g_path,'r') as f:\n",
        "    g_file = f.readlines()\n",
        "# remove header from file\n",
        "with open('embed_file.txt', 'w') as f:\n",
        "    f.writelines(g_file[1:])\n",
        "\n",
        "glove_model.read('embed_file.txt')\n",
        "print(f\"{g_path} file loaded!\")\n",
        "\n",
        "aug = naw.WordEmbsAug(\n",
        "    model_type='glove',\n",
        "    model=glove_model,\n",
        "    action=\"substitute\"\n",
        ")\n",
        "\n",
        "print(\"augmenter ready for use.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GloVe model...\n",
            "/content/drive/My Drive/data/glove_s100.txt file loaded!\n",
            "augmenter ready for use.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2tF3OyRB9hD"
      },
      "source": [
        "# create train and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "text_train, text_test, labels_train, labels_test = train_test_split(\n",
        "    text_data, label_data, test_size=0.1, random_state=123\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF-aEbkMCB6u"
      },
      "source": [
        "# tokenize sentences\n",
        "#Getting the maximum length of strings for truncation. (=141 in this case)\n",
        "max_length = int(np.mean([len(txt) for txt in text_data])) # média dos valores de tamanho de texto\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# create the Tokenizer object\n",
        "tokenizer = Tokenizer(num_words=20000,oov_token=oov_tok)\n",
        "# fit the tokenizer only to the training texts\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "# get the dictionary of word indexes\n",
        "word_index = tokenizer.word_index\n",
        "# tokenize and pad texts\n",
        "text_train = tokenizer.texts_to_sequences(text_train)\n",
        "text_test = tokenizer.texts_to_sequences(text_test)\n",
        "text_train = pad_sequences(text_train, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "text_test = pad_sequences(text_test, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te6WemjLHcXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5dad25a6-01d6-4239-97e4-bd108101e980"
      },
      "source": [
        "# export data\n",
        "data_path = '/content/drive/My Drive/data/'\n",
        "np.savez_compressed(f'{data_path}Training_Data.npz',text_train,labels_train)\n",
        "np.savez_compressed(f'{data_path}Test_Data.npz',text_test,labels_test)\n",
        "np.savez_compressed(f'{data_path}Word_Index.npz',word_index)\n",
        "print(f\"\\nPreprocessing finished! \\nFiles saved to {data_path}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preprocessing finished! \n",
            "Files saved to /content/drive/My Drive/data/.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNRI6jCNkKYZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f52de78-f124-4d04-985d-396b9c28ddca"
      },
      "source": [
        " # load data\n",
        " import numpy as np\n",
        " data_path = '/content/drive/My Drive/data/'\n",
        " text_train = np.load(f'{data_path}Training_Data.npz', allow_pickle=True)['arr_0']\n",
        " labels_train = np.load(f'{data_path}Training_Data.npz', allow_pickle=True)['arr_1']\n",
        " word_index = np.load(f'{data_path}Word_Index.npz', allow_pickle=True)['arr_0'].item()\n",
        " print('Files loaded!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aVC2idpID9N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "dc296940-4e82-411e-f533-ddaea574626b"
      },
      "source": [
        "# initialize pre-trained embedding matrix\n",
        "from tqdm import tqdm\n",
        "def load_embeddings(path_to_glove_file, vocab_dict):\n",
        "    embeddings = {}\n",
        "    with open(path_to_glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip(' ').split(' ')\n",
        "            w = values[0]\n",
        "            vectors = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[w] = vectors\n",
        "    vocab_size = len(vocab_dict)\n",
        "    embedding_size = len(embeddings[\"vetor\"])\n",
        "    embedding_matrix = np.random.uniform(-1, 1, size=(vocab_size, embedding_size))\n",
        "    num_loaded = 0\n",
        "\n",
        "    # if the word is in the glove vector database, then we load the pre-trained vetor\n",
        "    # but if it isn't we let the random values for later training\n",
        "    print(\"Initiating embeddings\")\n",
        "    for w, i in tqdm(vocab_dict.items()):\n",
        "        if embeddings.get(w) is not None:\n",
        "            v = embeddings.get(w)\n",
        "            if v != '<OOV>' and i < vocab_size:\n",
        "                embedding_matrix[i] = v\n",
        "                num_loaded += 1\n",
        "        else:\n",
        "            continue\n",
        "   \n",
        "    embedding_matrix = embedding_matrix.astype(np.float32)\n",
        "    return embedding_matrix\n",
        "\n",
        "#data_path = '.\\\\'\n",
        "pretrained_embs_file = 'glove_s100.txt'\n",
        "glove_embedding_matrix = load_embeddings(data_path+pretrained_embs_file,word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/17814 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "\n",
            "\n",
            " 10%|▉         | 1724/17814 [00:00<00:00, 17239.24it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initiating embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 18%|█▊        | 3240/17814 [00:00<00:00, 16553.01it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 4138/17814 [00:00<00:01, 13209.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 5906/17814 [00:00<00:00, 14292.34it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 7025/17814 [00:00<00:00, 12847.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 8909/17814 [00:00<00:00, 14198.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 10944/17814 [00:00<00:00, 15614.51it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 12487/17814 [00:00<00:00, 14196.87it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 14064/17814 [00:00<00:00, 14633.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 17814/17814 [00:01<00:00, 15348.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2MsXhRbI6QY"
      },
      "source": [
        "# saving embedding matrix\n",
        "np.savez(f'{data_path}{pretrained_embs_file.split(\".\")[0]}.npz', glove_embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZd5ELDaHvsh"
      },
      "source": [
        "# loading embedding matrix\n",
        "file_name = 'glove_s100.npz'\n",
        "glove_embedding_matrix = np.load(data_path+file_name, allow_pickle=True)['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "budpigxGJpPL"
      },
      "source": [
        "# building the Convolutional Neural Network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPool1D, Dense, Dropout, \\\n",
        "                                    concatenate, Embedding, Reshape, \\\n",
        "                                    Bidirectional, LSTM, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "def build_model(\n",
        "                window_sizes, feature_maps, sent_size, num_categs, num_depth, \n",
        "                layer_width, embedding_matrix:np.array, batch_norm=True\n",
        "                ):\n",
        "    inputs = Input(shape=(sent_size), dtype='float32', name='text_inputs') # dim = (BATCH_SIZE, sent_size, embedding_dim)\n",
        "    \n",
        "    # initialize the embeddings with my own embeddings matrix\n",
        "    embed = Embedding(31818, 100, \n",
        "                      mask_zero=True, input_length=sent_size, \n",
        "                      name='embedding_layer')(inputs)\n",
        "\n",
        "    #create array for max pooled vectors of features \n",
        "    ta = []\n",
        "\n",
        "    # as we have multiple window sizes:\n",
        "    for n_window in window_sizes:\n",
        "        con = Conv1D(feature_maps, n_window, padding='causal', \n",
        "                     activation=\"relu\", use_bias=True)(embed) # (BATCH_SIZE, sent_size-window_size+1, feature_maps)\n",
        "        # the convoluted tensor contains, for each window a feature map of dimension feature_maps\n",
        "        pooled = GlobalMaxPool1D(data_format='channels_last')(con) # (BATCH_SIZE, sent_size-windows_size+1)\n",
        "        # then, the max pooling operation extracts the maximum of each feature map, reducing the rank of the tensor\n",
        "        # the max pooled tensor contains a feature for each window\n",
        "        if batch_norm:\n",
        "            pooled = BatchNormalization(trainable=True)(pooled)\n",
        "        ta.append(pooled)\n",
        "    \n",
        "    concat = concatenate(ta, axis=1)\n",
        "    X = Dropout(0.5)(concat)\n",
        "    \n",
        "    #create the dense layers\n",
        "    for i in range(num_depth):\n",
        "        X = Dense(layer_width,activation=\"relu\",name=f\"dense_layer_{i}\")(X)\n",
        "        X = Dropout(0.5, name=f\"dropout_{i}\")(X)\n",
        "        X = BatchNormalization(trainable=True, name=f\"batch_norm_{i}\")(X)\n",
        "\n",
        "    outputs = Dense(num_categs,activation=\"softmax\",use_bias=True, kernel_regularizer=l2(l=3),\n",
        "                   kernel_constraint=Dropout(0.5))(X)\n",
        "    \n",
        "    # create the model\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    #return the model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81EPJL8cJWJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "31013d97-456f-4d82-987f-9664aba7840f"
      },
      "source": [
        "window_sizes = [2, 3, 4]\n",
        "feature_maps = 128\n",
        "num_categs = 5\n",
        "layer_width = 256\n",
        "num_depth = 1\n",
        "max_length = 191\n",
        "\n",
        "nlp_model = build_model(window_sizes, feature_maps, max_length, num_categs, \n",
        "                        num_depth, layer_width, glove_embedding_matrix)\n",
        "nlp_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_inputs (InputLayer)        [(None, 191)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer (Embedding)     (None, 191, 100)     3181800     text_inputs[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 191, 128)     25728       embedding_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 191, 128)     38528       embedding_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 191, 128)     51328       embedding_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 128)          0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128)          512         global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128)          512         global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128)          512         global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 384)          0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 384)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_layer_0 (Dense)           (None, 256)          98560       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_0 (Dropout)             (None, 256)          0           dense_layer_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_norm_0 (BatchNormalizatio (None, 256)          1024        dropout_0[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            1285        batch_norm_0[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,399,789\n",
            "Trainable params: 3,398,509\n",
            "Non-trainable params: 1,280\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvfjBLL7KARd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ab4ca14-db63-4754-c2ec-3e311ea35402"
      },
      "source": [
        "# Treinando o modelo\n",
        "\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "import os\n",
        "\n",
        "X_data = text_train\n",
        "y_data = labels_train\n",
        "\n",
        "opt = Adam()\n",
        "loss_fn = CategoricalCrossentropy()\n",
        "my_metrics = [\n",
        "           CategoricalAccuracy()\n",
        "]\n",
        "nlp_model.compile(optimizer = opt, loss = loss_fn, metrics = my_metrics)\n",
        "\n",
        "model_path = data_path+\"saved_nlp_model/\"\n",
        "if not os.path.isdir(model_path):\n",
        "    try:\n",
        "        os.mkdir(model_path)\n",
        "    except OSError:\n",
        "        print (\"\\nCreation of the directory %s failed \\n\" % model_path)\n",
        "    else:\n",
        "        print (\"\\nSuccessfully created the directory %s \\n\" % model_path)\n",
        "else:\n",
        "    print(\"\\nDirectory %s already exists\" % model_path)\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "\n",
        "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
        "checkpoint = ModelCheckpoint(data_path+'tf_ckpts/', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "history = nlp_model.fit(\n",
        "    X_data,\n",
        "    y_data,\n",
        "    batch_size = 200,\n",
        "    epochs = 100,\n",
        "    validation_split = 0.05,\n",
        "    verbose = 1,\n",
        "    callbacks = [checkpoint, early_stopping, learning_rate_scheduler]\n",
        ")\n",
        "\n",
        "nlp_model.save(model_path, save_format='tf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Directory /content/drive/My Drive/data/saved_nlp_model/ already exists\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 91s 728ms/step - loss: 11.3922 - categorical_accuracy: 0.4396 - val_loss: 3.0245 - val_categorical_accuracy: 0.5145 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 90s 724ms/step - loss: 1.6732 - categorical_accuracy: 0.6685 - val_loss: 1.7206 - val_categorical_accuracy: 0.4174 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 91s 724ms/step - loss: 1.2476 - categorical_accuracy: 0.7428 - val_loss: 1.6309 - val_categorical_accuracy: 0.6537 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 91s 727ms/step - loss: 1.0929 - categorical_accuracy: 0.8054 - val_loss: 1.4511 - val_categorical_accuracy: 0.7424 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 92s 733ms/step - loss: 0.9658 - categorical_accuracy: 0.8606 - val_loss: 1.1950 - val_categorical_accuracy: 0.7936 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 91s 729ms/step - loss: 0.8661 - categorical_accuracy: 0.9008 - val_loss: 1.0094 - val_categorical_accuracy: 0.8119 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 91s 731ms/step - loss: 0.7808 - categorical_accuracy: 0.9285 - val_loss: 0.9096 - val_categorical_accuracy: 0.8188 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 91s 730ms/step - loss: 0.7133 - categorical_accuracy: 0.9443 - val_loss: 0.8593 - val_categorical_accuracy: 0.8272 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 91s 729ms/step - loss: 0.6543 - categorical_accuracy: 0.9569 - val_loss: 0.8247 - val_categorical_accuracy: 0.8196 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 92s 732ms/step - loss: 0.6061 - categorical_accuracy: 0.9654 - val_loss: 0.8122 - val_categorical_accuracy: 0.8119 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 92s 734ms/step - loss: 0.5694 - categorical_accuracy: 0.9709 - val_loss: 0.7853 - val_categorical_accuracy: 0.8196 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 91s 732ms/step - loss: 0.5329 - categorical_accuracy: 0.9753 - val_loss: 0.7644 - val_categorical_accuracy: 0.8219 - lr: 9.0484e-04\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 91s 730ms/step - loss: 0.5051 - categorical_accuracy: 0.9794 - val_loss: 0.7670 - val_categorical_accuracy: 0.8165 - lr: 8.1873e-04\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 90s 724ms/step - loss: 0.4782 - categorical_accuracy: 0.9834 - val_loss: 0.7571 - val_categorical_accuracy: 0.8173 - lr: 7.4082e-04\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 91s 726ms/step - loss: 0.4570 - categorical_accuracy: 0.9862 - val_loss: 0.7490 - val_categorical_accuracy: 0.8188 - lr: 6.7032e-04\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 90s 717ms/step - loss: 0.4380 - categorical_accuracy: 0.9888 - val_loss: 0.7421 - val_categorical_accuracy: 0.8226 - lr: 6.0653e-04\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 90s 721ms/step - loss: 0.4250 - categorical_accuracy: 0.9891 - val_loss: 0.7365 - val_categorical_accuracy: 0.8173 - lr: 5.4881e-04\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 90s 721ms/step - loss: 0.4116 - categorical_accuracy: 0.9905 - val_loss: 0.7359 - val_categorical_accuracy: 0.8180 - lr: 4.9659e-04\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 90s 720ms/step - loss: 0.4024 - categorical_accuracy: 0.9915 - val_loss: 0.7310 - val_categorical_accuracy: 0.8173 - lr: 4.4933e-04\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 91s 724ms/step - loss: 0.3919 - categorical_accuracy: 0.9919 - val_loss: 0.7214 - val_categorical_accuracy: 0.8188 - lr: 4.0657e-04\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 90s 721ms/step - loss: 0.3840 - categorical_accuracy: 0.9929 - val_loss: 0.7156 - val_categorical_accuracy: 0.8165 - lr: 3.6788e-04\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 90s 721ms/step - loss: 0.3756 - categorical_accuracy: 0.9931 - val_loss: 0.7133 - val_categorical_accuracy: 0.8165 - lr: 3.3287e-04\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 90s 720ms/step - loss: 0.3713 - categorical_accuracy: 0.9933 - val_loss: 0.7108 - val_categorical_accuracy: 0.8219 - lr: 3.0119e-04\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 90s 720ms/step - loss: 0.3649 - categorical_accuracy: 0.9935 - val_loss: 0.7106 - val_categorical_accuracy: 0.8150 - lr: 2.7253e-04\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 90s 723ms/step - loss: 0.3582 - categorical_accuracy: 0.9943 - val_loss: 0.7013 - val_categorical_accuracy: 0.8265 - lr: 2.4660e-04\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 90s 718ms/step - loss: 0.3541 - categorical_accuracy: 0.9947 - val_loss: 0.7047 - val_categorical_accuracy: 0.8165 - lr: 2.2313e-04\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 90s 719ms/step - loss: 0.3485 - categorical_accuracy: 0.9947 - val_loss: 0.6996 - val_categorical_accuracy: 0.8211 - lr: 2.0190e-04\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 89s 716ms/step - loss: 0.3462 - categorical_accuracy: 0.9947 - val_loss: 0.7018 - val_categorical_accuracy: 0.8203 - lr: 1.8268e-04\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 89s 712ms/step - loss: 0.3422 - categorical_accuracy: 0.9958 - val_loss: 0.7014 - val_categorical_accuracy: 0.8196 - lr: 1.6530e-04\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/data/saved_nlp_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqWb32Z9grO_"
      },
      "source": [
        "labels_predict = nlp_model.predict(text_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRWsoy1hhCLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b2286f2-f789-4705-fb93-ea3f5d0e5db7"
      },
      "source": [
        "nlp_model.evaluate(text_test, labels_test, batch_size=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 2s 159ms/step - loss: 0.6847 - categorical_accuracy: 0.8332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.684732973575592, 0.8331613540649414]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH7VAwK2lm5L"
      },
      "source": [
        "def untokenize(tokenized_text_list, word_index):\n",
        "    index_word = {v: k for k, v in word_index.items()}\n",
        "\n",
        "    def untok_sent(text, index_word):\n",
        "        sent = []\n",
        "        for word in text:\n",
        "            if word != 0:\n",
        "                sent.append(index_word[word])\n",
        "        return \" \".join(sent)\n",
        "    \n",
        "    return [untok_sent(text, index_word) for text in tokenized_text_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "017ZFsiVnaAZ"
      },
      "source": [
        "def to_stars(label_list):\n",
        "    return ['*'*(int(lbl)+1) for lbl in label_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXhJohVth4gw"
      },
      "source": [
        "import pandas as pd\n",
        "predict_df = pd.DataFrame(\n",
        "    data=np.transpose(\n",
        "          [untokenize(text_test, word_index),\n",
        "          to_stars([np.argmax(lbl) for lbl in labels_predict]), \n",
        "          to_stars([np.argmax(lbl) for lbl in labels_test])\n",
        "          ]), \n",
        "    columns=['Texto (pré-processado)','Label predita','Label verdadeira']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joi_6-aeiA9B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2b816644-7ee9-4c09-965b-59d072ce4cd9"
      },
      "source": [
        "predict_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto (pré-processado)</th>\n",
              "      <th>Label predita</th>\n",
              "      <th>Label verdadeira</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eu achar que nao cumprir o que prometer na int...</td>\n",
              "      <td>**</td>\n",
              "      <td>**</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>espaco ter de sobra o motor nao e muito forte ...</td>\n",
              "      <td>**</td>\n",
              "      <td>**</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a porta da geladeira e do forno estao emperrar...</td>\n",
              "      <td>**</td>\n",
              "      <td>**</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>otimo e o melhor investimento que ja fiz ate h...</td>\n",
              "      <td>*****</td>\n",
              "      <td>*****</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>produto de baixa qualidade acabamento ruim e i...</td>\n",
              "      <td>**</td>\n",
              "      <td>**</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pelo amor nao comprar este merda investir 200 ...</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>excelente controle original e muito bonito</td>\n",
              "      <td>*****</td>\n",
              "      <td>*****</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>excelente produto de boa qualidade muito bem a...</td>\n",
              "      <td>*****</td>\n",
              "      <td>*****</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>produto bom mas ja foi aberto nao vir pelicula...</td>\n",
              "      <td>**</td>\n",
              "      <td>**</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>otimo produto apesar de vir somente no plastic...</td>\n",
              "      <td>*****</td>\n",
              "      <td>*****</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Texto (pré-processado)  ... Label verdadeira\n",
              "0  eu achar que nao cumprir o que prometer na int...  ...               **\n",
              "1  espaco ter de sobra o motor nao e muito forte ...  ...               **\n",
              "2  a porta da geladeira e do forno estao emperrar...  ...               **\n",
              "3  otimo e o melhor investimento que ja fiz ate h...  ...            *****\n",
              "4  produto de baixa qualidade acabamento ruim e i...  ...               **\n",
              "5  pelo amor nao comprar este merda investir 200 ...  ...                *\n",
              "6         excelente controle original e muito bonito  ...            *****\n",
              "7  excelente produto de boa qualidade muito bem a...  ...            *****\n",
              "8  produto bom mas ja foi aberto nao vir pelicula...  ...               **\n",
              "9  otimo produto apesar de vir somente no plastic...  ...            *****\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUAhJdASlSlU"
      },
      "source": [
        "nlp_loaded_model = tf.keras.models.load_model(data_path+'saved_nlp_model/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVjCEkfPj_hI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dac46eb9-2631-41ae-9225-530580d2ea29"
      },
      "source": [
        "nlp_loaded_model.evaluate(text_test, labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 3s 31ms/step - loss: 0.6847 - categorical_accuracy: 0.8332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6847328543663025, 0.8331613540649414]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQIPo4XcgaNW"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN9SbswQkvHO"
      },
      "source": [
        "# trying to augment the training set\n",
        "text_train_untok = untokenize(text_train,word_index)\n",
        "augmented_text_train = [aug.augment(text) for text in text_train_untok]\n",
        "text_train_aug = np.concatenate((text_train_untok, augmented_text_train))\n",
        "labels_train_aug = np.concatenate((labels_train, labels_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvIQDQCZqoZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "13a1e062-1062-4bea-ad38-ba7f4d0c1add"
      },
      "source": [
        "data_path = '/content/drive/My Drive/data/'\n",
        "np.savez_compressed(f'{data_path}Training_aug_Data.npz',text_train_aug,labels_train_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e7dad6efe30a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}Training_aug_Data.npz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_train_aug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    }
  ]
}